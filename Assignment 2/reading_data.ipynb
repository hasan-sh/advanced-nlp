{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbab12f-d279-4b4e-af94-637cce6ff0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4139308a-d774-4d55-adda-75aca9cd5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/en_ewt-up-train.conllu'\n",
    "test_file = '../data/en_ewt-up-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c19708-f841-4b42-8ba3-2bd7a733ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path, save_to_csv=False):\n",
    "    \"\"\"\n",
    "    This function reads a CoNLL-U format file and converts it into a pandas DataFrame.\n",
    "    Each row in the DataFrame corresponds to a token in the file, and columns\n",
    "    correspond to different features of the token, such as the token itself, its lemma, \n",
    "    part-of-speech tag, and syntactic dependency information.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the input CoNLL-U format file.\n",
    "    save_to_csv (bool): A boolean flag indicating whether to save the resulting DataFrame \n",
    "                        to a CSV file. Default is False.\n",
    "                        \n",
    "    Returns:\n",
    "    df (pandas.DataFrame): A pandas DataFrame containing the token-level information from\n",
    "                           the input file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open and read the input file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        train_data = f.read()\n",
    "    \n",
    "    # Split the file into individual documents, each separated by a blank line\n",
    "    data = []\n",
    "    for doc_i, doc in enumerate(train_data.split('\\n\\n')):\n",
    "        doc = doc.split('\\n')\n",
    "        sentences = ''\n",
    "        for line in doc:\n",
    "            # Skip lines starting with '#' (comment lines)\n",
    "            if line and line[0] != '#':\n",
    "                line = line.split('\\t')\n",
    "                line.insert(0, str(doc_i))\n",
    "                sentences += '\\t'.join(line) + '\\n'\n",
    "        data.append(sentences)\n",
    "    \n",
    "    # Create a pandas DataFrame from the token-level data\n",
    "    train_df = pd.DataFrame([x.split('\\t') for sent in data for x in sent.split('\\n') if x])\n",
    "    \n",
    "    # Rename the columns of the DataFrame\n",
    "    train_df = train_df.rename(columns={\n",
    "        0:'sent_id', \n",
    "        1:'token_id', \n",
    "        2:'token', \n",
    "        3:'lemma', \n",
    "        4:'POS', \n",
    "        5:'uni_POS',\n",
    "        6:'morph_type', \n",
    "        7:'distance_head', \n",
    "        8:'dep_label', \n",
    "        9:'dep_rel', \n",
    "        10:'space', \n",
    "        11:'probbank'\n",
    "    })\n",
    "    \n",
    "    # Convert the DataFrame from wide to long format\n",
    "    df = train_df.melt(\n",
    "        id_vars=[i for i in train_df.columns[:12]], \n",
    "        var_name=\"notneeded\", \n",
    "        value_name=\"target\"\n",
    "    )\n",
    "    \n",
    "    # Drop the 'notneeded' column and any rows that contain missing values\n",
    "    df.drop(['notneeded'], axis=1, inplace=True)\n",
    "    df = df[df['target'].notna()]\n",
    "    \n",
    "    # Optionally save the resulting DataFrame to a CSV file\n",
    "    if save_to_csv:\n",
    "        df.to_csv('../data/test.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    # Return the resulting DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d4a042-df70-46a3-9c3e-0fe29f747d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_data(test_file, save_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caa01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.min_rows', 200)\n",
    "# pd.set_option('display.max_rows', 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
