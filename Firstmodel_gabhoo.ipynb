{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasan-sh/advanced-nlp/blob/main/Firstmodel_gabhoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7cbab12f-d279-4b4e-af94-637cce6ff0cb",
      "metadata": {
        "id": "7cbab12f-d279-4b4e-af94-637cce6ff0cb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.metrics import *"
      ],
      "metadata": {
        "id": "EuJPshDtoHqb"
      },
      "id": "EuJPshDtoHqb",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hasan-sh/advanced-nlp.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WScyFUAFDrGl",
        "outputId": "bd15c231-29c5-4b20-d7e4-c8b4bfe15a6b"
      },
      "id": "WScyFUAFDrGl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'advanced-nlp' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I0iZzGdD2i6",
        "outputId": "510b4694-0abd-4a44-9c56-f3938e93ab48"
      },
      "id": "4I0iZzGdD2i6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4139308a-d774-4d55-adda-75aca9cd5713",
      "metadata": {
        "id": "4139308a-d774-4d55-adda-75aca9cd5713"
      },
      "outputs": [],
      "source": [
        "train_file = '/content/advanced-nlp/data/en_ewt-up-train.conllu'\n",
        "test_file = '/content/advanced-nlp/data/en_ewt-up-test.conllu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11c19708-f841-4b42-8ba3-2bd7a733ba61",
      "metadata": {
        "id": "11c19708-f841-4b42-8ba3-2bd7a733ba61"
      },
      "outputs": [],
      "source": [
        "def read_data(file_path, save_to_csv=False):\n",
        "    \"\"\"\n",
        "    This function reads a CoNLL-U format file and converts it into a pandas DataFrame.\n",
        "    Each row in the DataFrame corresponds to a token in the file, and columns\n",
        "    correspond to different features of the token, such as the token itself, its lemma, \n",
        "    part-of-speech tag, and syntactic dependency information.\n",
        "    \n",
        "    Parameters:\n",
        "    file_path (str): The path to the input CoNLL-U format file.\n",
        "    save_to_csv (bool): A boolean flag indicating whether to save the resulting DataFrame \n",
        "                        to a CSV file. Default is False.\n",
        "                        \n",
        "    Returns:\n",
        "    df (pandas.DataFrame): A pandas DataFrame containing the token-level information from\n",
        "                           the input file.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Open and read the input file\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        train_data = f.read()\n",
        "    \n",
        "    # Split the file into individual documents, each separated by a blank line\n",
        "    data = []\n",
        "    for doc_i, doc in enumerate(train_data.split('\\n\\n')):\n",
        "        doc = doc.split('\\n')\n",
        "        sentences = ''\n",
        "        for line in doc:\n",
        "            # Skip lines starting with '#' (comment lines)\n",
        "            if line and line[0] != '#':\n",
        "                line = line.split('\\t')\n",
        "                line.insert(0, str(doc_i))\n",
        "                sentences += '\\t'.join(line) + '\\n'\n",
        "        data.append(sentences)\n",
        "    \n",
        "    # Create a pandas DataFrame from the token-level data\n",
        "    train_df = pd.DataFrame([x.split('\\t') for sent in data for x in sent.split('\\n') if x])\n",
        "    \n",
        "    # Rename the columns of the DataFrame\n",
        "    train_df = train_df.rename(columns={\n",
        "        0:'sent_id', \n",
        "        1:'token_id', \n",
        "        2:'token', \n",
        "        3:'lemma', \n",
        "        4:'POS', \n",
        "        5:'uni_POS',\n",
        "        6:'morph_type', \n",
        "        7:'distance_head', \n",
        "        8:'dep_label', \n",
        "        9:'dep_rel', \n",
        "        10:'space', \n",
        "        11:'probbank'\n",
        "    })\n",
        "    \n",
        "    # Convert the DataFrame from wide to long format\n",
        "    df = train_df.melt(\n",
        "        id_vars=[i for i in train_df.columns[:12]], \n",
        "        var_name=\"notneeded\", \n",
        "        value_name=\"target\"\n",
        "    )\n",
        "    \n",
        "    # Drop the 'notneeded' column and any rows that contain missing values\n",
        "    #df[\"sent_id\"]=df['sent_id'].str.cat((df['notneeded'].astype(int)-12).astype(str) , sep=\"_\" )\n",
        "    df[\"repetion_id\"]=df[\"notneeded\"]-12\n",
        "    df.drop(['notneeded'], axis=1, inplace=True)\n",
        "    df = df[df['target'].notna()]\n",
        "    \n",
        "    # Optionally save the resulting DataFrame to a CSV file\n",
        "    if save_to_csv:\n",
        "        df.to_csv('/content/advanced-nlp/data/test.tsv', sep='\\t', index=False)\n",
        "    \n",
        "    # Return the resulting DataFrame\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d5d4a042-df70-46a3-9c3e-0fe29f747d4b",
      "metadata": {
        "id": "d5d4a042-df70-46a3-9c3e-0fe29f747d4b"
      },
      "outputs": [],
      "source": [
        "train = read_data(train_file,save_to_csv=True)\n",
        "test = read_data(test_file, save_to_csv=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_binary_label(df):\n",
        "  df = df.assign(label=[0 if target==\"_\" or target==\"V\" else 1 for target in df['target']])\n",
        "  df= df.drop('target', axis=1)\n",
        "  return df\n",
        "\n",
        "#clean column\n",
        "def columns_cleaning(df): #political choices inside\n",
        "  df=df[df[\"distance_head\"]!=\"_\"]#like this\n",
        "  df[\"distance_head\"]=df[\"distance_head\"].astype(int) #WARNING IS FROM HERE\n",
        "  \n",
        "  df[\"sent_id\"]=df[\"sent_id\"].astype(int) #WARNING IS FROM HERE\n",
        "\n",
        "  df= df.drop('token_id', axis=1) #or this\n",
        "  df=df[['sent_id', 'repetion_id','token', 'lemma', 'POS', 'uni_POS', 'morph_type',\n",
        "        'distance_head', 'dep_label', 'dep_rel', 'space', 'probbank' ,'label']]\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def make_NER(df):\n",
        "  return df\n",
        "\n",
        "cols_to_encode=[ 'token', 'lemma', 'POS', 'uni_POS',\n",
        "       'morph_type', 'dep_label', 'dep_rel', 'space',\n",
        "       'probbank']\n",
        "\n",
        "def create_encoding(df,cols_to_encode):\n",
        "  # create a LabelEncoder objec\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  # iterate over the columns to encode\n",
        "  for col in cols_to_encode:\n",
        "      df[col] = le.fit_transform(df[col])\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T_1k9SPRri2Y"
      },
      "id": "T_1k9SPRri2Y",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WITH ONLY TOKEN"
      ],
      "metadata": {
        "id": "fdE6rrG-mgRD"
      },
      "id": "fdE6rrG-mgRD"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train=train[[\"token\",\"target\"]]\n",
        "tokens_test=test[[\"token\",\"target\"]]"
      ],
      "metadata": {
        "id": "4__vk_VBRCqi"
      },
      "id": "4__vk_VBRCqi",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train=make_binary_label(tokens_train)\n",
        "tokens_test=make_binary_label(tokens_test)\n",
        "\n",
        "\n",
        "\n",
        "#cols_to_encode=['token']\n",
        "#tokens_train=create_encoding(tokens_train,cols_to_encode)\n",
        "#tokens_test=create_encoding(tokens_test,cols_to_encode)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(tokens_train['token'])\n",
        "X_test = vectorizer.transform(tokens_test['token'])\n",
        "y_train=tokens_train['label']\n",
        "y_test=tokens_test['label']\n"
      ],
      "metadata": {
        "id": "wiWehoZrEiV5"
      },
      "execution_count": 17,
      "outputs": [],
      "id": "wiWehoZrEiV5"
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "8dkEKrTiEiV-"
      },
      "execution_count": 17,
      "outputs": [],
      "id": "8dkEKrTiEiV-"
    },
    {
      "cell_type": "markdown",
      "source": [
        " MODEL"
      ],
      "metadata": {
        "id": "7UBBny8nMxmD"
      },
      "id": "7UBBny8nMxmD"
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the model\n",
        "log_regression = LogisticRegression(penalty='l2')\n",
        "\n",
        "#fit the model using the training data\n",
        "log_regression.fit(X_train,y_train)\n",
        "\n",
        "#use model to make predictions on test data\n",
        "y_pred = log_regression.predict(X_test)\n",
        "\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "prec = precision_score(y_test,y_pred)\n",
        "print(f\"{f1=}\")\n",
        "print(f\"{prec=}\")"
      ],
      "metadata": {
        "id": "-zNTlLupFcnm"
      },
      "id": "-zNTlLupFcnm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.sum()"
      ],
      "metadata": {
        "id": "jqmIJs6nFf51"
      },
      "id": "jqmIJs6nFf51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WITH BASIC FEATURES"
      ],
      "metadata": {
        "id": "HoGHIdlTnosD"
      },
      "id": "HoGHIdlTnosD"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##WRAPPER FUNCTION\n",
        "def process_dataset(df):\n",
        "  \n",
        "  df=make_binary_label(df)\n",
        "\n",
        "  df=columns_cleaning(df)\n",
        "\n",
        "  df=make_NER(df)\n",
        "\n",
        "  cols_to_encode=[ 'token', 'lemma', 'POS', 'uni_POS', 'morph_type', 'dep_label', 'dep_rel', 'space', 'probbank']\n",
        "  df=create_encoding(df,cols_to_encode)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "33GTzbx8N9io"
      },
      "id": "33GTzbx8N9io",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=process_dataset(train)\n",
        "df_test=process_dataset(test)\n"
      ],
      "metadata": {
        "id": "Mj7g4oGe9g24"
      },
      "id": "Mj7g4oGe9g24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=df_train\n",
        "y_train=X_train.pop('label')\n",
        "\n",
        "\n",
        "X_test=df_test\n",
        "y_test=X_test.pop('label')\n"
      ],
      "metadata": {
        "id": "RcxXwE99BAS_"
      },
      "id": "RcxXwE99BAS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE MODEL\n"
      ],
      "metadata": {
        "id": "qEWihzAMChpe"
      },
      "id": "qEWihzAMChpe"
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the model\n",
        "log_regression = LogisticRegression(penalty='l2')\n",
        "\n",
        "#fit the model using the training data\n",
        "log_regression.fit(X_train,y_train)\n",
        "\n",
        "#use model to make predictions on test data\n",
        "y_pred = log_regression.predict(X_test)\n",
        "\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "prec = precision_score(y_test,y_pred)\n",
        "print(f\"{f1=}\")\n",
        "print(f\"{prec=}\")\n"
      ],
      "metadata": {
        "id": "0gE8I6aaCk4a"
      },
      "id": "0gE8I6aaCk4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.sum()"
      ],
      "metadata": {
        "id": "Mv24xobnD-dV"
      },
      "id": "Mv24xobnD-dV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kuI77PH0Ck65"
      },
      "id": "kuI77PH0Ck65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOoo the issue is that keeps crashing if we put countvector or onehotvector along with other feature"
      ],
      "metadata": {
        "id": "WxRPXETRg6ec"
      },
      "id": "WxRPXETRg6ec"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WITH COUNTVECTOR TOKEN\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9E8l0QSbON8s"
      },
      "id": "9E8l0QSbON8s"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iyv6cmlzONWe"
      },
      "id": "Iyv6cmlzONWe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train=train\n",
        "tokens_test=test"
      ],
      "metadata": {
        "id": "T8MLiE7OOS58"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "T8MLiE7OOS58"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train=make_binary_label(tokens_train)\n",
        "tokens_test=make_binary_label(tokens_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "t_train=columns_cleaning(tokens_train)\n",
        "\n",
        "cols_to_encode=[ 'POS', 'uni_POS', 'morph_type', 'dep_label', 'dep_rel', 'space', 'probbank']\n",
        "t_train=create_encoding(t_train,cols_to_encode)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSVCv35VOS5-",
        "outputId": "5f8b6c6c-ab10-42c4-bf66-426029c8643a"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-cce8cf379759>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"distance_head\"]=df[\"distance_head\"].astype(int) #WARNING IS FROM HERE\n",
            "<ipython-input-127-cce8cf379759>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"sent_id\"]=df[\"sent_id\"].astype(int) #WARNING IS FROM HERE\n"
          ]
        }
      ],
      "id": "ZSVCv35VOS5-"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#cols_to_encode=['token']\n",
        "#tokens_train=create_encoding(tokens_train,cols_to_encode)\n",
        "#tokens_test=create_encoding(tokens_test,cols_to_encode)\n",
        "vectorizer = CountVectorizer()\n",
        "train_vec_token = vectorizer.fit_transform(t_train['token'])\n",
        "#test_vec_token = vectorizer.transform(tokens_test['token'])\n"
      ],
      "metadata": {
        "id": "ElwIkeeAP36E"
      },
      "id": "ElwIkeeAP36E",
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COLUMN TRANSFORMER"
      ],
      "metadata": {
        "id": "dwtocEY5W47H"
      },
      "id": "dwtocEY5W47H"
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GdcSIprcrNv",
        "outputId": "a933c1ee-ab0f-4a60-e3d3-5bd111519b5c"
      },
      "id": "2GdcSIprcrNv",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sent_id', 'token_id', 'token', 'lemma', 'POS', 'uni_POS', 'morph_type',\n",
              "       'distance_head', 'dep_label', 'dep_rel', 'space', 'probbank', 'target',\n",
              "       'repetion_id'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col=['sent_id', 'token_id', 'POS', 'uni_POS', 'morph_type',\n",
        "       'distance_head', 'dep_label', 'dep_rel', 'space', 'probbank', 'target',\n",
        "       'repetion_id']"
      ],
      "metadata": {
        "id": "R-7fIPCqXCr4"
      },
      "id": "R-7fIPCqXCr4",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttrain=train[col]\n",
        "ttest=test[col]"
      ],
      "metadata": {
        "id": "3gK5UMwkZtcc"
      },
      "id": "3gK5UMwkZtcc",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def columns_cleaning(df): #political choices inside\n",
        "  df=df[df[\"distance_head\"]!=\"_\"]#like this\n",
        "  df[\"distance_head\"]=df[\"distance_head\"].astype(int) #WARNING IS FROM HERE\n",
        "  \n",
        "  df[\"sent_id\"]=df[\"sent_id\"].astype(int) #WARNING IS FROM HERE\n",
        "\n",
        "  df= df.drop('token_id', axis=1) #or this\n",
        "  df=df[['sent_id', 'repetion_id','POS', 'uni_POS', 'morph_type',\n",
        "        'distance_head', 'dep_label', 'dep_rel', 'space', 'probbank' ,'label']]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "8EzBU9YRe6xs"
      },
      "id": "8EzBU9YRe6xs",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_encode=[ 'token', 'lemma', 'POS', 'uni_POS',\n",
        "       'morph_type', 'dep_label', 'dep_rel', 'space',\n",
        "       'probbank']\n",
        "\n",
        "def create_encoding(df,cols_to_encode):\n",
        "  # create a LabelEncoder objec\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  # iterate over the columns to encode\n",
        "  for col in cols_to_encode:\n",
        "      df[col] = le.fit_transform(df[col])\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "6daNSvRLfaK7"
      },
      "id": "6daNSvRLfaK7",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttrain=make_binary_label(ttrain)\n",
        "ttest=make_binary_label(ttest)\n",
        "\n",
        "ttrain=columns_cleaning(ttrain)\n",
        "ttest=columns_cleaning(ttest)\n",
        "\n",
        "col=[ 'POS', 'uni_POS',\n",
        "       'morph_type', 'dep_label', 'dep_rel', 'space',\n",
        "       'probbank']\n",
        "\n",
        "ttrain=create_encoding(ttrain,col)\n",
        "ttest=create_encoding(ttest,col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arnsCzvldWQB",
        "outputId": "bc2b00b7-91b5-4e7e-9788-95845332e2db"
      },
      "id": "arnsCzvldWQB",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-2295377dbcc6>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"distance_head\"]=df[\"distance_head\"].astype(int) #WARNING IS FROM HERE\n",
            "<ipython-input-32-2295377dbcc6>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"sent_id\"]=df[\"sent_id\"].astype(int) #WARNING IS FROM HERE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUOIc2HzeE-K"
      },
      "id": "RUOIc2HzeE-K",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=ttrain\n",
        "y_train=X_train.pop('label')\n",
        "\n",
        "\n",
        "X_test=ttest\n",
        "y_test=X_test.pop('label')\n"
      ],
      "metadata": {
        "id": "eMxhoo7AfJwH"
      },
      "execution_count": 35,
      "outputs": [],
      "id": "eMxhoo7AfJwH"
    },
    {
      "cell_type": "code",
      "source": [
        "ttrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "miJZWphhfOfZ",
        "outputId": "9a1d27fc-99a3-42ed-d0fd-f6c081049846"
      },
      "id": "miJZWphhfOfZ",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         sent_id repetion_id  POS  uni_POS  morph_type  distance_head  \\\n",
              "0              0           0   11       24          74              0   \n",
              "1              0           0   12       15         100              1   \n",
              "2              0           0   11       24          74              1   \n",
              "3              0           0   12        6         100              1   \n",
              "4              0           0    0       17          41              6   \n",
              "...          ...         ...  ...      ...         ...            ...   \n",
              "7077906     7506          34   15       41          90            123   \n",
              "7077907     7506          34    4        9         100            134   \n",
              "7077908     7506          34   10       29          36            134   \n",
              "7077909     7506          34   15       42          63              4   \n",
              "7077910     7506          34    7       23          74            134   \n",
              "\n",
              "         dep_label  dep_rel  space  probbank  \n",
              "0               46        0     30         1  \n",
              "1               44     3130     30         1  \n",
              "2               25     2995     31         1  \n",
              "3               44     3130     31         1  \n",
              "4                4     9101     31         1  \n",
              "...            ...      ...    ...       ...  \n",
              "7077906          2      756     31      1238  \n",
              "7077907          9     1097     31         1  \n",
              "7077908         35     1098     31         1  \n",
              "7077909         14     7504     31      1300  \n",
              "7077910         38     1099     31         1  \n",
              "\n",
              "[1035904 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e54ef88-ad24-4561-9cb6-10cffad9a09b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>repetion_id</th>\n",
              "      <th>POS</th>\n",
              "      <th>uni_POS</th>\n",
              "      <th>morph_type</th>\n",
              "      <th>distance_head</th>\n",
              "      <th>dep_label</th>\n",
              "      <th>dep_rel</th>\n",
              "      <th>space</th>\n",
              "      <th>probbank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>3130</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>2995</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>3130</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>9101</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077906</th>\n",
              "      <td>7506</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>41</td>\n",
              "      <td>90</td>\n",
              "      <td>123</td>\n",
              "      <td>2</td>\n",
              "      <td>756</td>\n",
              "      <td>31</td>\n",
              "      <td>1238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077907</th>\n",
              "      <td>7506</td>\n",
              "      <td>34</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>100</td>\n",
              "      <td>134</td>\n",
              "      <td>9</td>\n",
              "      <td>1097</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077908</th>\n",
              "      <td>7506</td>\n",
              "      <td>34</td>\n",
              "      <td>10</td>\n",
              "      <td>29</td>\n",
              "      <td>36</td>\n",
              "      <td>134</td>\n",
              "      <td>35</td>\n",
              "      <td>1098</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077909</th>\n",
              "      <td>7506</td>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>42</td>\n",
              "      <td>63</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>7504</td>\n",
              "      <td>31</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077910</th>\n",
              "      <td>7506</td>\n",
              "      <td>34</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>74</td>\n",
              "      <td>134</td>\n",
              "      <td>38</td>\n",
              "      <td>1099</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1035904 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e54ef88-ad24-4561-9cb6-10cffad9a09b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e54ef88-ad24-4561-9cb6-10cffad9a09b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e54ef88-ad24-4561-9cb6-10cffad9a09b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE MODEL\n"
      ],
      "metadata": {
        "id": "bMTwc5n_fJwP"
      },
      "id": "bMTwc5n_fJwP"
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the model\n",
        "log_regression = LogisticRegression(penalty='l2')\n",
        "\n",
        "#fit the model using the training data\n",
        "log_regression.fit(X_train,y_train)\n",
        "\n",
        "#use model to make predictions on test data\n",
        "y_pred = log_regression.predict(X_test)\n",
        "\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "prec = precision_score(y_test,y_pred)\n",
        "print(f\"{f1=}\")\n",
        "print(f\"{prec=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsAlu4QHfJwU",
        "outputId": "6724b21c-c5b0-4fce-c091-425105cdf42e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1=0.0\n",
            "prec=0.0\n"
          ]
        }
      ],
      "id": "WsAlu4QHfJwU"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAh4H1nfzwZ",
        "outputId": "cd5d2bfd-89ba-4e55-df67-032d7de7982b"
      },
      "id": "jLAh4H1nfzwZ",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F94ZS3CMgwO6"
      },
      "id": "F94ZS3CMgwO6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COLUMNT TRANSFORMER ATTEMPT"
      ],
      "metadata": {
        "id": "xIjLhGYzgw35"
      },
      "id": "xIjLhGYzgw35"
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer([(\"token_vec\", OneHotEncoder(), [\"token\"])], remainder=\"passthrough\",sparse_threshold=0)"
      ],
      "metadata": {
        "id": "HkFZRud7Xyhy"
      },
      "id": "HkFZRud7Xyhy",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ct.fit_transform(ttrain)"
      ],
      "metadata": {
        "id": "f83epUUxZ9iU"
      },
      "id": "f83epUUxZ9iU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4l3BM69a09Q",
        "outputId": "e4ef6bcf-08d3-443c-b1be-79a814a8d221"
      },
      "id": "Z4l3BM69a09Q",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103246, 4880)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH6ylYHRbRXh",
        "outputId": "290f214a-4763-4713-94c9-1ac8451f861f"
      },
      "id": "fH6ylYHRbRXh",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103246, 4881)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}