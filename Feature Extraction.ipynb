{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e2ea65-72eb-4040-98df-2d8f5d493b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from features import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ffdaf9-099d-498c-8e07-a77a4ce6994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9f72dc-a925-41b8-abab-316d09a24ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"We are all in the gutter, but some of us are looking at the stars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577bb3ec-4b84-4c55-a4bd-1abd8317e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 15:15:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a79b47555e24cefb8b79751742a1eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 15:15:26 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2023-02-14 15:15:26 INFO: Use device: cpu\n",
      "2023-02-14 15:15:26 INFO: Loading: tokenize\n",
      "2023-02-14 15:15:26 INFO: Loading: pos\n",
      "2023-02-14 15:15:26 INFO: Loading: lemma\n",
      "2023-02-14 15:15:26 INFO: Loading: ner\n",
      "2023-02-14 15:15:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "basic_fe = extract_features(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbb4daa-3b47-4451-ba68-eb68e68cbc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ner</th>\n",
       "      <th>stemming</th>\n",
       "      <th>pos_bigram</th>\n",
       "      <th>token_bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We</td>\n",
       "      <td>PRON</td>\n",
       "      <td>we</td>\n",
       "      <td></td>\n",
       "      <td>we</td>\n",
       "      <td>PRON_AUX</td>\n",
       "      <td>We_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be</td>\n",
       "      <td></td>\n",
       "      <td>are</td>\n",
       "      <td>AUX_ADV</td>\n",
       "      <td>are_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>ADV</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>all</td>\n",
       "      <td>ADV_ADP</td>\n",
       "      <td>all_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td>in</td>\n",
       "      <td>ADP_DET</td>\n",
       "      <td>in_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "      <td>DET_NOUN</td>\n",
       "      <td>the_gutter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gutter</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gutter</td>\n",
       "      <td></td>\n",
       "      <td>gutter</td>\n",
       "      <td>NOUN_PUNCT</td>\n",
       "      <td>gutter_,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT_CCONJ</td>\n",
       "      <td>,_but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>but</td>\n",
       "      <td></td>\n",
       "      <td>but</td>\n",
       "      <td>CCONJ_DET</td>\n",
       "      <td>but_some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>some</td>\n",
       "      <td>DET</td>\n",
       "      <td>some</td>\n",
       "      <td></td>\n",
       "      <td>some</td>\n",
       "      <td>DET_ADP</td>\n",
       "      <td>some_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "      <td>of</td>\n",
       "      <td>ADP_PRON</td>\n",
       "      <td>of_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>us</td>\n",
       "      <td>PRON</td>\n",
       "      <td>we</td>\n",
       "      <td></td>\n",
       "      <td>us</td>\n",
       "      <td>PRON_AUX</td>\n",
       "      <td>us_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be</td>\n",
       "      <td></td>\n",
       "      <td>are</td>\n",
       "      <td>AUX_VERB</td>\n",
       "      <td>are_looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>looking</td>\n",
       "      <td>VERB</td>\n",
       "      <td>look</td>\n",
       "      <td></td>\n",
       "      <td>look</td>\n",
       "      <td>VERB_ADP</td>\n",
       "      <td>looking_at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>at</td>\n",
       "      <td></td>\n",
       "      <td>at</td>\n",
       "      <td>ADP_DET</td>\n",
       "      <td>at_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "      <td>DET_NOUN</td>\n",
       "      <td>the_stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stars</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>star</td>\n",
       "      <td></td>\n",
       "      <td>star</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    pos   lemma ner stemming   pos_bigram token_bigram\n",
       "0        We   PRON      we           we     PRON_AUX       We_are\n",
       "1       are    AUX      be          are      AUX_ADV      are_all\n",
       "2       all    ADV     all          all      ADV_ADP       all_in\n",
       "3        in    ADP      in           in      ADP_DET       in_the\n",
       "4       the    DET     the          the     DET_NOUN   the_gutter\n",
       "5    gutter   NOUN  gutter       gutter   NOUN_PUNCT     gutter_,\n",
       "6         ,  PUNCT       ,            ,  PUNCT_CCONJ        ,_but\n",
       "7       but  CCONJ     but          but    CCONJ_DET     but_some\n",
       "8      some    DET    some         some      DET_ADP      some_of\n",
       "9        of    ADP      of           of     ADP_PRON        of_us\n",
       "10       us   PRON      we           us     PRON_AUX       us_are\n",
       "11      are    AUX      be          are     AUX_VERB  are_looking\n",
       "12  looking   VERB    look         look     VERB_ADP   looking_at\n",
       "13       at    ADP      at           at      ADP_DET       at_the\n",
       "14      the    DET     the          the     DET_NOUN    the_stars\n",
       "15    stars   NOUN    star         star                          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_fe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
